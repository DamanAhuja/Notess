# Adv Algo
# ğŸ“˜ **UNIT 1 â€” List & Iterator ADTs**

**Topics Covered:**

* Abstract Data Types (ADT)
* Vectors
* Lists
* Sequences
* Iterators
  *(4 Hours â€“ But extremely foundational for all later units)*

---

## ğŸ”¹ 1. ABSTRACT DATA TYPE (ADT)

### âœ… Definition

An **Abstract Data Type (ADT)** is a *logical description of a data structure*, focusing on:

* What operations can be performed
* NOT how they are implemented

ğŸ‘‰ It hides the internal representation and shows only behavior.

---

### âœ… ADT vs Data Structure

| ADT             | Data Structure                 |
| --------------- | ------------------------------ |
| Logical concept | Physical implementation        |
| What operations | How operations are implemented |
| Example: List   | Example: Array, Linked List    |

---

### âœ… Example of List ADT (Conceptual)

Operations:

* insert(x)
* delete(pos)
* search(x)
* size()
* isEmpty()

Implementation can be:

* Array List
* Linked List

---

âœ… **Exam Line:**

> ADT provides data abstraction and separates the userâ€™s view from the implementation.

---

## ğŸ”¹ 2. VECTOR ADT

### âœ… Definition

A **Vector** is a **dynamic array** that:

* Stores elements in **contiguous memory**
* Automatically **resizes**
* Supports **random access**

---

### âœ… Core Operations

| Operation    | Description               | Time Complexity |
| ------------ | ------------------------- | --------------- |
| at(i)        | Access element at index i | O(1)            |
| insert(i, x) | Insert at index           | O(n)            |
| push_back(x) | Add at end                | O(1) amortized  |
| pop_back()   | Remove last element       | O(1)            |
| size()       | Number of elements        | O(1)            |
| capacity()   | Allocated memory          | O(1)            |

---

### âœ… Dynamic Resizing Concept

When capacity is full:

1. New array of **double size**
2. Copy all elements
3. Old array deleted

âœ… This is why insertion at end is **amortized O(1)** not worst-case.

---

### âœ… Advantages

âœ” Fast access
âœ” Cache friendly
âœ” Easy to implement

### âœ… Disadvantages

âŒ Slow insertion/deletion in middle
âŒ Memory wastage due to unused capacity

---

## ğŸ”¹ 3. LIST ADT

### âœ… Definition

A **List** is a **linear collection of elements** where:

* Elements have a **position**
* Access is generally **sequential**

---

### âœ… List ADT Operations

| Operation    | Meaning                |
| ------------ | ---------------------- |
| insert(i, x) | Insert at position i   |
| remove(i)    | Remove from position i |
| get(i)       | Get element at i       |
| find(x)      | Search element         |
| isEmpty()    | Check if empty         |
| size()       | Count elements         |

---

## ğŸ”¹ 4. TYPES OF LIST IMPLEMENTATION

---

### âœ… (A) ARRAY LIST

* Stored in contiguous memory
* Fixed size or dynamic array

| Operation     | Time |
| ------------- | ---- |
| Access        | O(1) |
| Insert/Delete | O(n) |
| Search        | O(n) |

âœ… Used when:

* Fast access needed
* Insertions are less frequent

---

### âœ… (B) LINKED LIST

Each node has:

* Data
* Next pointer

Types:

* Singly Linked List
* Doubly Linked List
* Circular Linked List

---

#### âœ… Singly Linked List Node

```
[Data | Next]
```

| Operation           | Time |
| ------------------- | ---- |
| Insert at beginning | O(1) |
| Delete at beginning | O(1) |
| Search              | O(n) |
| Access by index     | O(n) |

---

### âœ… Comparison: Array List vs Linked List

| Feature        | Array List | Linked List    |
| -------------- | ---------- | -------------- |
| Memory         | Contiguous | Non-contiguous |
| Access         | O(1)       | O(n)           |
| Insert/Delete  | O(n)       | O(1)           |
| Cache Friendly | Yes        | No             |

---

## ğŸ”¹ 5. SEQUENCE ADT

### âœ… Definition

A **Sequence** is a **generalization of vector + list**, supporting:

* Element access by index
* Insertion & deletion
* Iterator traversal

ğŸ‘‰ It combines features of both vector and list.

---

### âœ… Operations

* at(i)
* insert(i, x)
* erase(i)
* begin()
* end()
* size()

---

âœ… Implemented using:

* Arrays
* Linked Lists
* Deques

---

## ğŸ”¹ 6. ITERATOR ADT (VERY IMPORTANT FOR EXAMS ğŸ”¥)

### âœ… Definition

An **Iterator** is an object that:

* Points to an element in a container
* Allows traversal without exposing internal structure

---

### âœ… Why Iterators Are Needed?

âœ” Uniform traversal
âœ” Data structure independence
âœ” Works for all containers
âœ” Safer than raw pointers

---

### âœ… Basic Iterator Operations

| Operation  | Meaning            |
| ---------- | ------------------ |
| begin()    | First element      |
| end()      | After last element |
| ++it       | Move forward       |
| *it        | Access value       |
| it1 == it2 | Compare            |

---

### âœ… Example Concept (C++ Style)

```
for(it = v.begin(); it != v.end(); it++) {
    print(*it);
}
```

---

### âœ… Types of Iterators (Theoretical)

| Type          | Movement           |
| ------------- | ------------------ |
| Input         | Read only, forward |
| Output        | Write only         |
| Forward       | Read + Write       |
| Bidirectional | Forward + Backward |
| Random Access | Jump anywhere      |

---

## ğŸ”¹ 7. RELATION BETWEEN VECTOR, LIST, SEQUENCE & ITERATOR

| Structure | Supports Random Access | Uses Iterator |
| --------- | ---------------------- | ------------- |
| Vector    | âœ… Yes                  | âœ… Yes         |
| List      | âŒ No                   | âœ… Yes         |
| Sequence  | âœ… Yes                  | âœ… Yes         |

---

## ğŸ”¹ 8. APPLICATIONS (VERY IMPORTANT FOR LONG ANSWERS)

* Vectors â†’ Dynamic memory, graphics, simulations
* Lists â†’ Undo operations, browser history
* Sequences â†’ Text editors, playlists
* Iterators â†’ STL traversal, databases

---

## ğŸ”¹ 9. COMMON EXAM QUESTIONS FROM UNIT 1

### âœ… 2 Marks:

* Define ADT
* What is a Vector?
* Define Iterator
* What is a List?

---

### âœ… 5 Marks:

* Compare Vector and List
* Explain Dynamic Resizing in Vector
* Explain Sequence ADT
* Advantages of Iterators

---

### âœ… 10 Marks:

* Explain List ADT and its implementations in detail
* Explain Vector ADT with operations and complexity
* Write detailed notes on Iterator ADT

---

# ğŸ“˜ **UNIT 2 â€” HASH TABLES & DICTIONARIES**

**Topics Covered:**

* Dictionaries
* Hash Tables
* Hash Functions
* Collision Resolution Techniques
  *(6 Hours â€“ VERY important & scoring unit)*

---

## ğŸ”¹ 1. DICTIONARY ADT

### âœ… Definition

A **Dictionary (or Map)** is an ADT that stores **(key, value)** pairs such that:

* Each **key is unique**
* Each key maps to exactly one value

---

### âœ… Dictionary Operations

| Operation    | Meaning                 |
| ------------ | ----------------------- |
| insert(k, v) | Insert key-value pair   |
| remove(k)    | Delete entry with key k |
| search(k)    | Return value of key k   |
| size()       | Number of entries       |
| isEmpty()    | Check if empty          |

---

### âœ… Real-Life Examples

* Roll number â†’ Student name
* Account number â†’ Balance
* Word â†’ Meaning

---

âœ… **Exam Line:**

> A dictionary is a dynamic set supported with insertion, deletion and search based on keys.

---

## ğŸ”¹ 2. NEED FOR HASH TABLES

Traditional Searching:

* Array â†’ O(n)
* Linked List â†’ O(n)
* Binary Search â†’ O(log n) *(requires sorted data)*

âœ… **Hash Table provides average O(1) time** for:

* Insertion
* Deletion
* Searching

Thatâ€™s why it is widely used in:

* Databases
* Compilers
* Password storage
* Caches

---

## ğŸ”¹ 3. HASH TABLE â€” DEFINITION

### âœ… Definition

A **Hash Table** is a data structure that:

* Uses a **hash function** to map keys to array indices
* Stores elements at computed positions

```
Index = h(key)
```

---

### âœ… Structure of Hash Table

| Component     | Description                |
| ------------- | -------------------------- |
| Key           | Input value                |
| Hash Function | Converts key â†’ index       |
| Table         | Array where data is stored |

---

## ğŸ”¹ 4. HASH FUNCTION (VERY IMPORTANT ğŸ”¥)

### âœ… Definition

A **Hash Function** is a function that maps a key into a table index.

```
h(k) â†’ {0, 1, 2, ..., m-1}
```

where `m = table size`

---

### âœ… Properties of a Good Hash Function

âœ” Uniform distribution
âœ” Fast computation
âœ” Minimum collisions
âœ” Deterministic (same key â†’ same index)

---

### âœ… Types of Hash Functions

---

### 1ï¸âƒ£ Division Method

```
h(k) = k mod m
```

âœ… Most commonly used
âœ… Choose `m` as a prime number

---

### 2ï¸âƒ£ Mid-Square Method

* Square the key
* Extract middle digits

âœ… More uniform distribution

---

### 3ï¸âƒ£ Multiplication Method

```
h(k) = âŒŠ m (kA mod 1) âŒ‹
```

where `0 < A < 1`

âœ… Less clustering

---

### 4ï¸âƒ£ Folding Method

* Split key into parts
* Add them together

âœ… Used for large numeric keys

---

## ğŸ”¹ 5. COLLISION â€” HEART OF UNIT 2 ğŸ”¥

### âœ… Definition

A **collision occurs when two different keys map to the same index**.

```
h(k1) = h(k2)
```

---

### âœ… Why Collisions Occur?

* Limited table size
* Poor hash function
* Large number of keys

---

## ğŸ”¹ 6. COLLISION RESOLUTION TECHNIQUES

---

# âœ… (A) SEPARATE CHAINING

### âœ… Concept

Each table index stores a **linked list of elements**.

```
Table[5] â†’ [key1 â†’ key2 â†’ key3]
```

---

### âœ… Operations & Complexity

| Operation | Average | Worst |
| --------- | ------- | ----- |
| Insert    | O(1)    | O(n)  |
| Search    | O(1)    | O(n)  |
| Delete    | O(1)    | O(n)  |

---

### âœ… Advantages

âœ” Simple
âœ” No overflow problem
âœ” Easy deletion

### âœ… Disadvantages

âŒ Extra memory for pointers
âŒ Poor cache utilization

---

# âœ… (B) OPEN ADDRESSING

All elements are stored **inside the hash table itself**.

If collision occurs â†’ find another empty slot.

---

## ğŸ”¹ 1. Linear Probing

```
h(k, i) = (h(k) + i) mod m
```

Try one by one next slot.

---

### âœ… Problem: Primary Clustering

Consecutive occupied slots form large clusters.

---

## ğŸ”¹ 2. Quadratic Probing

```
h(k, i) = (h(k) + iÂ²) mod m
```

Reduces clustering.

---

## ğŸ”¹ 3. Double Hashing

```
h(k, i) = (h1(k) + i*h2(k)) mod m
```

âœ… Best probing technique
âœ… Least clustering

---

## ğŸ”¹ 7. LOAD FACTOR (Î±) â€” VERY IMPORTANT EXAM TERM

### âœ… Definition

```
Î± = n / m
```

where

* `n` = number of keys
* `m` = table size

---

### âœ… Effect of Load Factor

| Î± Value | Performance     |
| ------- | --------------- |
| Small   | Faster          |
| Large   | More collisions |

---

âœ… In Open Addressing:

```
Î± < 0.7 is recommended
```

---

## ğŸ”¹ 8. REHASHING

### âœ… Definition

When load factor becomes too large:

1. Create a **new table with double size**
2. Reinsert all keys using new hash function

âœ… Improves performance

---

## ğŸ”¹ 9. COMPARISON OF COLLISION TECHNIQUES

| Feature     | Chaining | Open Addressing |
| ----------- | -------- | --------------- |
| Memory      | More     | Less            |
| Deletion    | Easy     | Difficult       |
| Performance | Stable   | Depends on Î±    |
| Overflow    | Never    | Possible        |

---

## ğŸ”¹ 10. APPLICATIONS OF HASH TABLES

* Password Authentication
* Symbol Tables in Compilers
* Database Indexing
* Caching
* Blockchain
* Networks

---

## ğŸ”¹ 11. TIME COMPLEXITY SUMMARY

| Operation | Average | Worst |
| --------- | ------- | ----- |
| Insert    | O(1)    | O(n)  |
| Search    | O(1)    | O(n)  |
| Delete    | O(1)    | O(n)  |

---

## ğŸ”¹ 12. COMMON EXAM QUESTIONS (VERY PREDICTABLE âœ…)

### âœ… 2 Marks:

* Define Hash Table
* What is Collision?
* Define Load Factor
* What is a Dictionary?

---

### âœ… 5 Marks:

* Explain Hash Function
* Explain Collision Resolution
* Explain Chaining
* Explain Linear Probing
* What is Rehashing?

---

### âœ… 10 Marks:

* Explain Hash Tables with all collision techniques
* Compare Chaining and Open Addressing
* Explain Open Addressing methods in detail
* Explain Hash Function and its properties

---


# ğŸ“• **UNIT 3 â€” STRINGS & TRIES (8 HOURS)**

### âœ… Topics Covered:

* String Basics
* String Matching
* **KMP Algorithm**
* Tries

  * Standard Tries
  * Compressed Tries
  * **Suffix Tries**
* Applications in **Search Engines**

---

# ğŸ”¹ 1. STRING â€” BASIC CONCEPT

### âœ… Definition

A **String** is a sequence of characters taken from a finite alphabet.

Example:

```
"algorithm", "data", "school"
```

---

### âœ… String Operations

| Operation        | Purpose                        |
| ---------------- | ------------------------------ |
| Length           | Total characters               |
| Compare          | Lexicographic comparison       |
| Substring        | Extract part                   |
| Concatenate      | Join two strings               |
| Pattern Matching | Find one string inside another |

---

âœ… **Core Problem in this Unit:**

> Efficient **Pattern Searching in a Text**

---

# ğŸ”¹ 2. STRING MATCHING PROBLEM

### âœ… Definition

Given:

* **Text T** of length `n`
* **Pattern P** of length `m`

Find all positions where `P` occurs in `T`.

Example:

```
T = ABABDABACDABABCABAB
P = ABABCABAB
```

---

## âŒ Naive String Matching Algorithm

### âœ… Idea

Match pattern at every position of text.

### âœ… Time Complexity

```
O(n Ã— m)   âŒ (Very slow for large data)
```

---

âœ… This inefficiency leads to the development of **KMP Algorithm** âœ…

---

# ğŸ”¥ 3. KMP (KNUTHâ€“MORRISâ€“PRATT) ALGORITHM â€” VERY IMPORTANT ğŸ”¥ğŸ”¥ğŸ”¥

### âœ… Purpose

To avoid unnecessary comparisons while matching the pattern.

âœ… It uses a **preprocessed table (LPS array)**.

---

## âœ… Key Idea of KMP

When a mismatch occurs:

* Do **NOT restart from beginning of pattern**
* Shift pattern using **LPS array**

---

## ğŸ”¹ 3.1 LPS ARRAY (Longest Prefix Suffix)

### âœ… Definition

For each index `i` in pattern:

```
LPS[i] = length of longest proper prefix
         which is also a suffix
```

---

### âœ… Example

Pattern:

```
A B A B C A B A B
0 1 2 3 4 5 6 7 8
```

LPS Array:

```
0 0 1 2 0 1 2 3 4
```

---

### âœ… How LPS Helps?

It tells:

> "How many characters we can safely skip after mismatch"

---

## ğŸ”¹ 3.2 KMP ALGORITHM STEPS

### âœ… Step 1: Build LPS Array

Time: `O(m)`

### âœ… Step 2: Match Pattern with Text

Time: `O(n)`

---

### âœ… Total Time Complexity

```
O(n + m) âœ…âœ…âœ…
```

---

## ğŸ”¹ 3.3 KMP DRY RUN (Exam Favorite ğŸ”¥)

Text:

```
ABABDABACDABABCABAB
```

Pattern:

```
ABABCABAB
```

1. Precompute LPS
2. Match character by character
3. On mismatch â†’ jump using LPS
4. Pattern found at correct index

âœ… **Examiner checks your understanding using this dry run**

---

## âœ… KMP SUMMARY

| Feature         | Value                                 |
| --------------- | ------------------------------------- |
| Preprocessing   | Yes                                   |
| Time Complexity | O(n+m)                                |
| Extra Space     | O(m)                                  |
| Applications    | Text search, Plagiarism, DNA matching |

---

# ğŸ”¹ 4. TRIE DATA STRUCTURE (VERY VERY IMPORTANT ğŸ”¥)

---

## âœ… Definition

A **Trie (Prefix Tree)** is a tree-based data structure used to store **strings efficiently**.

Each node:

* Represents a **character**
* Paths represent **words**

---

### âœ… Example Words:

```
cat, car, cap
```

```
        (root)
        /   \
       c
       |
       a
     /  |  \
    t   r   p
```

---

## ğŸ”¹ 4.1 TRIE OPERATIONS

| Operation | Time |
| --------- | ---- |
| Insert    | O(L) |
| Search    | O(L) |
| Delete    | O(L) |

where `L = length of word`

---

## ğŸ”¹ 4.2 INSERT OPERATION IN TRIE

* Start from root
* For each character:

  * If exists â†’ move forward
  * Else â†’ create node

---

## ğŸ”¹ 4.3 SEARCH OPERATION IN TRIE

* Traverse character by character
* If any character missing â†’ word not present

---

## âœ… Advantages of Trie

âœ” Fast searching
âœ” No collisions
âœ” Ideal for prefix searching
âœ” Works better than hash tables for strings

---

## âŒ Disadvantages

âŒ High memory usage
âŒ Not cache friendly

---

# ğŸ”¹ 5. COMPRESSED TRIE (PATTERN TRIE)

### âœ… Definition

A **Compressed Trie** removes unnecessary single-child chains by compressing edges.

---

### âœ… Benefit

âœ” Saves memory
âœ” Faster traversal
âœ” Used in large dictionary systems

---

# ğŸ”¥ 6. SUFFIX TRIE (VERY IMPORTANT ğŸ”¥ğŸ”¥ğŸ”¥)

---

## âœ… Definition

A **Suffix Trie** is a Trie that stores **all suffixes of a string**.

---

### âœ… Example

String:

```
BANANA
```

Suffixes:

```
BANANA  
ANANA  
NANA  
ANA  
NA  
A
```

All inserted into a Trie âœ…

---

## âœ… Applications of Suffix Trie

| Application                | Use  |
| -------------------------- | ---- |
| Pattern searching          | O(m) |
| Longest repeated substring | Yes  |
| DNA sequence matching      | Yes  |
| Plagiarism detection       | Yes  |

---

## âœ… Time & Space Complexity

| Feature      | Value |
| ------------ | ----- |
| Construction | O(nÂ²) |
| Search       | O(m)  |
| Space        | O(nÂ²) |

---

# ğŸ”¹ 7. TRIE vs HASH TABLE (VERY COMMON EXAM QUESTION âœ…)

| Feature       | Trie  | Hash Table |
| ------------- | ----- | ---------- |
| Prefix Search | âœ… Yes | âŒ No       |
| Speed         | O(L)  | O(1)       |
| Memory        | High  | Low        |
| Collision     | No    | Yes        |

---

# ğŸ”¹ 8. ROLE OF TRIES IN SEARCH ENGINES

---

## âœ… Search Engine Tasks

* Auto-suggest
* Auto-complete
* Spell check
* Keyword matching
* Fast lookup

âœ… All powered using:

* **Tries**
* **Compressed Tries**
* **Suffix Tries**

---

### âœ… Example:

Typing:

```
"go"
```

Suggestions:

```
google, good, govt, gold
```

---

# ğŸ”¹ 9. APPLICATIONS OF STRING MATCHING & TRIES

* Google Search
* DNA Matching
* Plagiarism Detection
* Compiler token matching
* Spam Detection
* Pattern Recognition

---

# ğŸ”¹ 10. COMPLETE TIME COMPLEXITY SUMMARY

| Algorithm         | Time   |
| ----------------- | ------ |
| Naive Matching    | O(nm)  |
| KMP               | O(n+m) |
| Trie Insert       | O(L)   |
| Trie Search       | O(L)   |
| Suffix Trie Build | O(nÂ²)  |

---

# ğŸ”¹ 11. MOST IMPORTANT EXAM QUESTIONS âœ…âœ…âœ…

---

## âœ… 2 Marks

* Define String Matching
* What is LPS?
* What is a Trie?
* Define Suffix Trie

---

## âœ… 5 Marks

* Explain KMP Algorithm
* Explain Trie with example
* Applications of Trie
* Difference between Trie & Hash Table

---

## âœ… 10 Marks (VERY HIGH PROBABILITY ğŸ”¥)

1. Explain **KMP Algorithm with example and dry run**
2. Explain **Trie Data Structure with operations**
3. Explain **Suffix Trie with construction**
4. Role of **Trie in Search Engines**

---

# ğŸ“˜ **UNIT 4 â€” MORE ON TREES (8 HOURS)**

### âœ… Topics Covered:

* **2â€“4 Trees (also called 2â€“3â€“4 Trees)**
* **B-Trees**

These trees are the **foundation of database indexing, file systems, and large-scale storage systems**.

---

# ğŸ”¹ 1. WHY DO WE NEED ADVANCED TREES?

### âŒ Problems with Binary Search Trees (BST)

* Can become **skewed**
* Worst-case time = **O(n)**
* Not suitable for **disk-based storage**

---

### âœ… Solution â†’ Self-Balancing Multiway Trees

* **2â€“4 Trees**
* **B-Trees**

âœ” Always balanced
âœ” Height is kept minimum
âœ” Guaranteed **O(log n)** operations

---

# ğŸ”¥ 2. 2â€“4 TREE (2â€“3â€“4 TREE)

---

## âœ… Definition

A **2â€“4 Tree** is a **self-balancing multiway search tree** in which each node can have:

| Node Type | Keys   | Children   |
| --------- | ------ | ---------- |
| 2-node    | 1 key  | 2 children |
| 3-node    | 2 keys | 3 children |
| 4-node    | 3 keys | 4 children |

---

### âœ… Properties of 2â€“4 Tree

1. All leaves are at the **same level** âœ…
2. Each node can have **1 to 3 keys**
3. Each internal node can have **2 to 4 children**
4. It is always **perfectly height-balanced**
5. Keys inside a node are always in **sorted order**

---

## ğŸ”¹ 2.1 SEARCH IN 2â€“4 TREE

### âœ… Steps:

1. Compare key with node keys
2. Move to correct child
3. Repeat until found or reach leaf

---

### âœ… Time Complexity:

```
O(log n)
```

---

## ğŸ”¹ 2.2 INSERTION IN 2â€“4 TREE (VERY IMPORTANT ğŸ”¥)

### âœ… Basic Idea

* Always insert at a **leaf node**
* If leaf becomes **overflow (4 keys)** â†’ split it

---

### âœ… Splitting a 4-Node

If a node has:

```
[a | b | c]
```

After inserting new key â†’ overflow (4 keys)

Steps:

1. Middle key **b moves up**
2. Left key goes to **left child**
3. Right key goes to **right child**

âœ… Tree remains balanced

---

### âœ… Special Case: Root Split

If **root splits**, a new root is created â†’ **tree height increases by 1**

---

### âœ… Insertion Time:

```
O(log n)
```

---

## ğŸ”¹ 2.3 DELETION IN 2â€“4 TREE (THEORY LEVEL)

Deletion is done carefully to:

* Avoid **node having 0 keys**
* Borrow from sibling or
* Merge nodes when required

âœ… Still remains balanced
âœ… Time complexity: **O(log n)**

---

## ğŸ”¹ 2.4 ADVANTAGES OF 2â€“4 TREES

âœ” Always balanced
âœ” Guaranteed log time for search, insert, delete
âœ” Used as the **basis of Red-Black Trees**
âœ” Better than BST for large datasets

---

## ğŸ”¹ 2.5 DISADVANTAGES

âŒ Complex implementation
âŒ Not directly used in databases
âŒ High memory overhead

---

# ğŸ”¥ 3. B-TREE (MOST IMPORTANT TREE FOR EXAMS ğŸ”¥ğŸ”¥ğŸ”¥)

---

## âœ… Definition

A **B-Tree** is a **generalized, self-balancing m-ary search tree** designed for **disk storage and databases**.

---

## âœ… Order of B-Tree (m)

A B-Tree of order **m** means:

| Property                | Rule           |
| ----------------------- | -------------- |
| Max children            | m              |
| Max keys                | m âˆ’ 1          |
| Min children (non-root) | âŒˆm/2âŒ‰          |
| Min keys                | âŒˆm/2âŒ‰ âˆ’ 1      |
| Root special case       | Can have fewer |

---

## ğŸ”¹ 3.1 PROPERTIES OF B-TREE (EXAM DEFINITIONS âœ…)

1. All leaves appear at the **same level**
2. Keys in a node are in **sorted order**
3. Every node has **at most (mâˆ’1) keys**
4. Every internal node has **at most m children**
5. Except root, every node has **at least âŒˆm/2âŒ‰ children**
6. Height of B-Tree is always **O(log n)**

---

# ğŸ”¹ 3.2 SEARCH IN B-TREE

### âœ… Steps:

1. Start from root
2. Perform **binary search within node**
3. Move to correct child
4. Repeat until found or leaf reached

---

### âœ… Time Complexity:

```
O(log n)
```

---

# ğŸ”¥ 3.3 INSERTION IN B-TREE (VERY HIGH PROBABILITY ğŸ”¥)

---

### âœ… Step 1: Insert Like BST

* Find correct leaf
* Insert in sorted order

---

### âœ… Step 2: Handle Overflow

If node gets **m keys â†’ overflow**

âœ… Split the node:

* Middle key moves up
* Left part â†’ left child
* Right part â†’ right child

---

### âœ… Root Split Case

If root overflows:

* Create a **new root**
* Increase height by 1

---

### âœ… Insertion Complexity:

```
O(log n)
```

---

# ğŸ”¥ 3.4 DELETION IN B-TREE (IMPORTANT THEORY)

---

### âœ… Three Cases of Deletion

---

### âœ… Case 1: Key in Leaf Node

* Simply delete
* If underflow occurs â†’ borrow or merge

---

### âœ… Case 2: Key in Internal Node

* Replace with:

  * Inorder predecessor OR
  * Inorder successor
* Then delete that key from leaf

---

### âœ… Case 3: Underflow Handling

If node has **less than minimum keys**:

* **Borrow from sibling**
* OR **Merge with sibling**

---

### âœ… Deletion Complexity:

```
O(log n)
```

---

# ğŸ”¹ 4. B-TREE vs 2â€“4 TREE (VERY COMMON EXAM QUESTION âœ…)

| Feature      | 2â€“4 Tree     | B-Tree       |
| ------------ | ------------ | ------------ |
| Type         | Special case | General case |
| Max children | 4            | m            |
| Disk usage   | No           | âœ… Yes        |
| Used in DB   | âŒ No         | âœ… Yes        |
| Height       | Logarithmic  | Logarithmic  |

âœ… **2â€“4 tree is a special case of B-Tree where m = 4**

---

# ğŸ”¹ 5. B-TREE vs BINARY SEARCH TREE âœ…

| Feature     | BST            | B-Tree          |
| ----------- | -------------- | --------------- |
| Balance     | Not guaranteed | Always balanced |
| Height      | O(n) worst     | O(log n)        |
| Disk access | Poor           | Excellent       |
| Use in DB   | âŒ No           | âœ… Yes           |

---

# ğŸ”¹ 6. APPLICATIONS OF B-TREES

ğŸ”¥ Very Important for exams

* Database indexing (MySQL, Oracle)
* File systems (NTFS, ext4)
* Large block storage
* Operating systems
* Data warehouses

---

# ğŸ”¹ 7. TIME COMPLEXITY SUMMARY

| Operation | 2â€“4 Tree | B-Tree   |
| --------- | -------- | -------- |
| Search    | O(log n) | O(log n) |
| Insert    | O(log n) | O(log n) |
| Delete    | O(log n) | O(log n) |

---

# ğŸ”¹ 8. MOST IMPORTANT EXAM QUESTIONS âœ…âœ…âœ…

---

### âœ… 2 Marks

* Define 2â€“4 Tree
* Define B-Tree
* What is order of B-Tree?

---

### âœ… 5 Marks

* Properties of 2â€“4 Tree
* Advantages of B-Tree
* Compare BST and B-Tree
* Applications of B-Tree

---

### âœ… 10 Marks (ğŸ”¥ Guaranteed)

1. Explain **2â€“4 Tree with insertion and properties**
2. Explain **B-Tree with insertion and deletion**
3. Compare **2â€“4 Tree and B-Tree**
4. Explain **Applications of B-Tree in databases**

---

# ğŸ“˜ **UNIT 5 â€” ADVANCED GRAPHS (8 HOURS)**

### âœ… Topics Covered:

* Graph Basics (Quick Revision)
* **Bellmanâ€“Ford Algorithm**
* **Unionâ€“Find Data Structure**
* **Kruskalâ€™s Algorithm**
* Applications & Complexity

---

# ğŸ”¹ 1. GRAPH â€” QUICK FOUNDATION (EXAM REVISION)

---

## âœ… Definition

A **Graph G** is defined as:

```
G = (V, E)
```

where

* `V` = set of vertices (nodes)
* `E` = set of edges (connections)

---

## âœ… Types of Graphs

| Type               | Description             |
| ------------------ | ----------------------- |
| Undirected         | Edges have no direction |
| Directed (Digraph) | Edges have direction    |
| Weighted           | Edges have weights      |
| Unweighted         | All edges equal         |

---

## âœ… Graph Representations

### 1ï¸âƒ£ Adjacency Matrix

* Space: `O(VÂ²)`
* Fast lookup

### 2ï¸âƒ£ Adjacency List

* Space: `O(V + E)`
* Used in most algorithms âœ…

---

# ğŸ”¥ 2. BELLMANâ€“FORD ALGORITHM (VERY IMPORTANT)

---

## âœ… Purpose

Find the **shortest path from a single source to all other vertices**
âœ… Works with **negative edge weights**
âŒ Detects **negative weight cycles**

---

## âœ… Difference from Dijkstra

| Feature          | Dijkstra   | Bellman-Ford |
| ---------------- | ---------- | ------------ |
| Negative weights | âŒ No       | âœ… Yes        |
| Time complexity  | O(E log V) | O(VE)        |
| Cycle detection  | âŒ No       | âœ… Yes        |

---

## ğŸ”¹ 2.1 PRINCIPLE OF BELLMANâ€“FORD

* Relax all edges **(V âˆ’ 1) times**
* Because max edges in shortest path = `V âˆ’ 1`

---

## ğŸ”¹ 2.2 RELAXATION PROCESS

For each edge `(u, v)` with weight `w`:

```
if dist[u] + w < dist[v]
    dist[v] = dist[u] + w
```

---

## ğŸ”¹ 2.3 ALGORITHM STEPS (EXAM FORM)

1. Initialize:

   ```
   dist[source] = 0
   all others = âˆ
   ```

2. Repeat **(V âˆ’ 1) times**:

   * For each edge â†’ Relax it

3. Negative Cycle Check:

   * If any edge still relaxes â†’ **negative cycle exists**

---

## âœ… Time Complexity

```
O(V Ã— E)
```

âœ… Space Complexity

```
O(V)
```

---

## âœ… Applications of Bellmanâ€“Ford

* GPS navigation with penalties
* Network routing (RIP protocol)
* Currency exchange arbitrage detection
* Graphs with negative weights

---

# ğŸ”¥ 3. UNIONâ€“FIND (DISJOINT SET DATA STRUCTURE)

This is the **backbone of Kruskalâ€™s Algorithm** âœ…

---

## âœ… Definition

Unionâ€“Find is a data structure that keeps track of:

* **Disjoint sets**
* Supports:

  * `Find(x)`
  * `Union(x, y)`

---

## ğŸ”¹ 3.1 OPERATIONS

---

### âœ… FIND(x)

Returns the **representative (root)** of the set.

---

### âœ… UNION(x, y)

Joins the sets containing `x` and `y`.

---

## ğŸ”¹ 3.2 TWO OPTIMIZATIONS (VERY IMPORTANT ğŸ”¥)

---

### âœ… 1ï¸âƒ£ Path Compression

While finding root, make all nodes point directly to root.

âœ… Makes tree flat â†’ faster operations

---

### âœ… 2ï¸âƒ£ Union by Rank

Always attach **smaller tree under bigger tree**

âœ… Prevents skewed trees

---

## âœ… Time Complexity (With Both Optimizations)

```
O(Î±(n)) â‰ˆ O(1)
```

(Î± is inverse Ackermann â€” nearly constant)

---

## âœ… Applications of Unionâ€“Find

* Kruskalâ€™s Algorithm
* Network connectivity
* Cycle detection
* Image processing
* Social network groups

---

# ğŸ”¥ 4. KRUSKALâ€™S ALGORITHM (MOST IMPORTANT ALGORITHM ğŸ”¥ğŸ”¥ğŸ”¥)

---

## âœ… Purpose

Find the **Minimum Spanning Tree (MST)** of a connected, undirected, weighted graph.

---

## âœ… Definition: Minimum Spanning Tree

An MST:

* Connects **all vertices**
* Has **V âˆ’ 1 edges**
* Has **minimum total weight**
* Contains **no cycles**

---

## ğŸ”¹ 4.1 PRINCIPLE OF KRUSKAL

1. Sort all edges by **increasing weight**
2. Pick the smallest edge
3. If it **does NOT form a cycle**, include it
4. Repeat until **V âˆ’ 1 edges chosen**

---

## ğŸ”¹ 4.2 ROLE OF UNIONâ€“FIND IN KRUSKAL

| Task              | Unionâ€“Find Use |
| ----------------- | -------------- |
| Cycle detection   | âœ…              |
| Component merging | âœ…              |
| Fast operations   | âœ…              |

---

## ğŸ”¹ 4.3 ALGORITHM STEPS (EXAM FORM)

1. Sort edges by weight
2. Initialize Unionâ€“Find
3. For each edge `(u, v)`:

   * If `Find(u) â‰  Find(v)`

     * Add edge to MST
     * `Union(u, v)`
4. Stop when MST has `V - 1` edges

---

## âœ… Time Complexity

```
O(E log E)
```

(Because sorting dominates)

---

## âœ… Space Complexity

```
O(V)
```

---

## âœ… Applications of Kruskal

* Road & bridge networks
* Circuit design
* Computer networks
* Water pipelines
* Cluster analysis

---

# ğŸ”¥ 5. COMPARISON QUESTIONS (VERY COMMON)

---

## âœ… Bellmanâ€“Ford vs Dijkstra

| Feature          | Bellmanâ€“Ford | Dijkstra |
| ---------------- | ------------ | -------- |
| Negative weights | âœ… Yes        | âŒ No     |
| Cycle detection  | âœ… Yes        | âŒ No     |
| Speed            | Slower       | Faster   |

---

## âœ… Kruskal vs Prim (MST)

| Feature         | Kruskal       | Prim           |
| --------------- | ------------- | -------------- |
| Works best for  | Sparse graphs | Dense graphs   |
| Uses            | Edge sorting  | Priority queue |
| Cycle detection | Unionâ€“Find    | Not required   |

---

## âœ… Graph Algorithm Summary Table

| Algorithm    | Purpose               | Time       |
| ------------ | --------------------- | ---------- |
| Bellmanâ€“Ford | Shortest path         | O(VE)      |
| Unionâ€“Find   | Set management        | ~O(1)      |
| Kruskal      | Minimum Spanning Tree | O(E log E) |

---

# ğŸ”¹ 6. MOST IMPORTANT EXAM QUESTIONS âœ…âœ…âœ…

---

## âœ… 2 Marks

* Define Graph
* What is MST?
* What is Unionâ€“Find?
* What is a negative weight cycle?

---

## âœ… 5 Marks

* Explain Bellmanâ€“Ford Algorithm
* Explain Unionâ€“Find with example
* Applications of Kruskal
* Difference between Kruskal and Prim

---

## âœ… 10 Marks (ğŸ”¥ VERY HIGH PROBABILITY)

1. Explain **Bellmanâ€“Ford Algorithm with example**
2. Explain **Unionâ€“Find with optimizations**
3. Explain **Kruskalâ€™s Algorithm with step-by-step working**
4. Compare **Bellmanâ€“Ford & Dijkstra**
5. Minimal Spanning Tree using Kruskal

---

# ğŸ“˜ **UNIT 6 â€” RANDOMIZATION (6 HOURS)**

### âœ… Topics Covered:

* Concept of Randomized Algorithms
* **Randomized Quicksort**
* **Randomized Select**
* **Skip Lists**

These algorithms use **randomness to improve average performance and avoid worst-case inputs**.

---

# ğŸ”¹ 1. RANDOMIZED ALGORITHMS â€” CORE IDEA

---

## âœ… Definition

A **Randomized Algorithm** is an algorithm that makes **random choices during execution** to improve:

* Average performance
* Simplicity
* Resistance to worst-case inputs

---

### âœ… Two Types of Randomized Algorithms

| Type        | Description                                                   |
| ----------- | ------------------------------------------------------------- |
| Las Vegas   | Always correct result, but running time is random             |
| Monte Carlo | Fast result, but may give wrong answer with small probability |

---

### âœ… Examples in Your Syllabus

* **Randomized Quicksort â†’ Las Vegas**
* **Randomized Select â†’ Las Vegas**
* **Skip Lists â†’ Las Vegas**

âœ… All algorithms in your unit are **Las Vegas type** (always correct âœ…)

---

### âœ… Advantages of Randomization

âœ” Avoids worst-case inputs
âœ” Better average performance
âœ” Simpler implementation
âœ” Used in cryptography, networking, AI

---

# ğŸ”¥ 2. RANDOMIZED QUICKSORT (VERY IMPORTANT)

---

## ğŸ”¹ 2.1 REVISION: NORMAL QUICKSORT

* Uses **divide and conquer**
* Picks a **pivot**
* Partitions array into:

  * Left < pivot
  * Right > pivot

---

### âŒ Problem:

If pivot is always bad (like first or last element in sorted array):

```
Worst Case Time = O(nÂ²)
```

---

# âœ… SOLUTION â†’ RANDOMIZED QUICKSORT

---

## âœ… Idea

Instead of a fixed pivot:

> Choose a **random element as pivot**

This makes worst-case **extremely unlikely**.

---

## ğŸ”¹ 2.2 ALGORITHM STEPS

1. Randomly choose an index `r`
2. Swap `A[r]` with `A[high]`
3. Apply normal partition process
4. Recursively sort left & right subarrays

---

## âœ… Time Complexity

| Case         | Time              |
| ------------ | ----------------- |
| Best case    | O(n log n)        |
| Average case | âœ… **O(n log n)**  |
| Worst case   | O(nÂ²) (very rare) |

âœ… In practice â†’ behaves like **O(n log n)** always.

---

## âœ… Space Complexity

```
O(log n)  (Recursive stack)
```

---

## âœ… Advantages

âœ” Avoids bad input cases
âœ” Faster than Merge Sort in practice
âœ” In-place sorting
âœ” Widely used in real systems

---

## âœ… Applications

* System sorting functions
* Competitive programming
* Database sorting

---

# ğŸ”¥ 3. RANDOMIZED SELECT (FIND káµ—Ê° SMALLEST ELEMENT)

---

## âœ… Problem Definition

Given an unsorted array, find:

> The **káµ—Ê° smallest element**

Example:

```
A = [7, 4, 1, 3, 9, 6]
k = 3 â†’ Answer = 3
```

---

## âœ… Idea Behind Randomized Select

* Based on **Randomized Quicksort Partition**
* After partition:

  * If pivot position = k â†’ answer found
  * Else recurse only on one side

âœ… Unlike Quicksort â†’ only one side is explored

---

## ğŸ”¹ 3.1 ALGORITHM STEPS

1. Choose random pivot
2. Partition array
3. Let pivot index = `i`

* If `i == k` â†’ return A[i]
* If `i > k` â†’ recurse on left
* If `i < k` â†’ recurse on right

---

## âœ… Time Complexity

| Case    | Time              |
| ------- | ----------------- |
| Best    | O(n)              |
| Average | âœ… **O(n)**        |
| Worst   | O(nÂ²) (very rare) |

âœ… This is **much faster than sorting the full array**

---

## âœ… Applications

* Median finding
* Statistical analysis
* Ranking systems
* Data mining

---

# ğŸ”¥ 4. SKIP LIST (MOST IMPORTANT THEORY STRUCTURE ğŸ”¥ğŸ”¥ğŸ”¥)

---

## âœ… Definition

A **Skip List** is a **probabilistic data structure** that allows:

* Searching
* Insertion
* Deletion

in **O(log n) average time**, like balanced trees, but with:
âœ… Simpler implementation

---

### âœ… Idea

Instead of one linked list:

* Multiple levels of linked lists are maintained
* Higher levels â€œskipâ€ many elements

---

## ğŸ”¹ 4.1 STRUCTURE OF SKIP LIST

Example (Conceptual):

Level 3 â†’  1 -------- 9
Level 2 â†’  1 ---- 5 ---- 9
Level 1 â†’  1 - 3 - 5 - 7 - 9
Level 0 â†’  1 2 3 4 5 6 7 8 9

Higher levels have **fewer elements**.

---

## ğŸ”¹ 4.2 SEARCH IN SKIP LIST

1. Start at **top-left**
2. Move right while value is smaller
3. If next is larger â†’ move down
4. Continue until found or reach bottom

---

## ğŸ”¹ 4.3 INSERTION IN SKIP LIST

1. Insert in **normal linked list (level 0)**
2. Flip a **coin**:

   * If head â†’ go to next level
   * If tail â†’ stop

âœ… This randomness decides the height of towers

---

## ğŸ”¹ 4.4 DELETION IN SKIP LIST

* Remove the node from all levels
* Very similar to deletion in linked lists

---

## âœ… Time Complexity of Skip List

| Operation | Average    | Worst |
| --------- | ---------- | ----- |
| Search    | O(log n) âœ… | O(n)  |
| Insert    | O(log n) âœ… | O(n)  |
| Delete    | O(log n) âœ… | O(n)  |

âœ… Worst case is very rare due to randomness.

---

## âœ… Advantages of Skip Lists

âœ” Easier than balanced trees
âœ” Dynamic structure
âœ” No rotations required
âœ” Used in databases & Redis

---

## âŒ Disadvantages

âŒ Extra memory for pointers
âŒ Dependent on randomness

---

# ğŸ”¥ 5. RANDOMIZED ALGORITHMS vs DETERMINISTIC ALGORITHMS

| Feature              | Randomized           | Deterministic  |
| -------------------- | -------------------- | -------------- |
| Behavior             | Uses randomness      | Fixed behavior |
| Worst-case guarantee | âŒ No                 | âœ… Yes          |
| Average performance  | âœ… Excellent          | âœ… Good         |
| Example              | Randomized Quicksort | Merge Sort     |

---

# ğŸ”¹ 6. APPLICATIONS OF RANDOMIZATION

* Cryptography
* Load balancing
* Distributed systems
* AI & ML sampling
* Network routing
* Cache replacement

---

# ğŸ”¹ 7. COMPLETE TIME COMPLEXITY SUMMARY

| Algorithm            | Best       | Average      | Worst |
| -------------------- | ---------- | ------------ | ----- |
| Randomized Quicksort | O(n log n) | âœ… O(n log n) | O(nÂ²) |
| Randomized Select    | O(n)       | âœ… O(n)       | O(nÂ²) |
| Skip List            | O(log n)   | âœ… O(log n)   | O(n)  |

---

# ğŸ”¹ 8. MOST IMPORTANT EXAM QUESTIONS âœ…âœ…âœ…

---

## âœ… 2 Marks

* Define Randomized Algorithm
* What is Skip List?
* Define Randomized Quicksort

---

## âœ… 5 Marks

* Explain Randomized Select
* Explain Skip List with advantages
* Difference between Deterministic & Randomized algorithms

---

## âœ… 10 Marks (ğŸ”¥ VERY HIGH PROBABILITY)

1. Explain **Randomized Quicksort with time complexity**
2. Explain **Randomized Select Algorithm**
3. Explain **Skip List with operations and complexity**
4. Compare **Skip List and Balanced Trees**

---

# ğŸ“˜ **UNIT 7 â€” NETWORK FLOWS & FORDâ€“FULKERSON ALGORITHM (5 HOURS)**

### âœ… Topics Covered:

* Flow Network
* Flow, Capacity, Residual Graph
* Augmenting Path
* **Fordâ€“Fulkerson Algorithm**
* Applications
* Time Complexity

This unit is **small but extremely scoring**, especially for **numerical problems** âœ…

---

# ğŸ”¹ 1. FLOW NETWORK â€” BASIC CONCEPT

---

## âœ… Definition

A **Flow Network** is a **directed graph**:

```
G = (V, E)
```

With:

* A **source node (S)**
* A **sink node (T)**
* Each edge has a **capacity c(u, v)**

---

### âœ… Rules of Flow Network

1. Graph is **directed**
2. Each edge has **capacity â‰¥ 0**
3. Flow moves from **S â†’ T**
4. No flow can exceed edge capacity

---

### âœ… Example (Conceptual)

```
S â†’ A â†’ T  
S â†’ B â†’ T
```

Each edge has a fixed capacity.

---

# ğŸ”¹ 2. FLOW IN A NETWORK

---

## âœ… Definition

A **flow f(u, v)** is the amount of data sent from node `u` to `v` such that:

### âœ… Flow Constraints

1. **Capacity Constraint**

```
0 â‰¤ f(u, v) â‰¤ c(u, v)
```

2. **Flow Conservation**
   For every node except S and T:

```
Incoming Flow = Outgoing Flow
```

3. **Total Flow**
   Flow out of source = Flow into sink

---

# ğŸ”¹ 3. RESIDUAL CAPACITY & RESIDUAL GRAPH (VERY IMPORTANT ğŸ”¥)

---

## âœ… Residual Capacity

Remaining capacity on an edge:

```
Residual(u, v) = c(u, v) âˆ’ f(u, v)
```

---

## âœ… Residual Graph

A graph that shows:

* Remaining forward capacity
* Possible backward flow

âœ… This graph is **used to find new augmenting paths**

---

# ğŸ”¹ 4. AUGMENTING PATH

---

## âœ… Definition

An **Augmenting Path** is a path from **S to T** in the **residual graph** where:

* All edges have **positive residual capacity**

---

### âœ… Why Itâ€™s Important?

Each augmenting path allows us to **increase the total flow** âœ…

---

# ğŸ”¥ 5. FORDâ€“FULKERSON ALGORITHM (MOST IMPORTANT ğŸ”¥ğŸ”¥ğŸ”¥)

---

## âœ… Purpose

To find the **maximum possible flow from source (S) to sink (T)**.

---

## âœ… Core Idea

> Repeatedly find **augmenting paths** and increase the flow until no more exist.

---

## ğŸ”¹ 5.1 FORDâ€“FULKERSON ALGORITHM STEPS (EXAM FORMAT âœ…)

---

### âœ… Step 1:

Initialize all flows to **0**

---

### âœ… Step 2:

Construct the **residual graph**

---

### âœ… Step 3:

Find an **augmenting path** from **S to T**

---

### âœ… Step 4:

Find the **minimum residual capacity (bottleneck)** on that path

---

### âœ… Step 5:

Add this flow to all edges of that path

---

### âœ… Step 6:

Update the residual graph

---

### âœ… Step 7:

Repeat until **no more augmenting paths exist**

---

âœ… The final total flow is the **Maximum Flow** âœ…

---

# ğŸ”¹ 5.2 BOTTLENECK CAPACITY

---

## âœ… Definition

The **bottleneck** is the **minimum residual capacity on the augmenting path**.

This value determines:

> How much extra flow can be pushed through that path.

---

# ğŸ”¹ 5.3 TERMINATION CONDITION

Algorithm stops when:

> âŒ No path exists from **S to T** in residual graph.

At this point â†’ **Maximum Flow is achieved** âœ…

---

# ğŸ”¹ 6. TIME COMPLEXITY OF FORDâ€“FULKERSON

---

| Version                 | Time Complexity    |
| ----------------------- | ------------------ |
| Basic Fordâ€“Fulkerson    | **O(E Ã— MaxFlow)** |
| With BFS (Edmondsâ€“Karp) | **O(V Ã— EÂ²)**      |

âœ… Many universities write:

```
O(E Ã— f)
where f = maximum flow
```

---

# ğŸ”¥ 7. APPLICATIONS OF MAX FLOW (VERY IMPORTANT FOR EXAMS âœ…)

---

| Field              | Use                       |
| ------------------ | ------------------------- |
| Computer Networks  | Data packet routing       |
| Transportation     | Traffic flow              |
| Job Assignment     | Bipartite matching        |
| Project Management | Resource allocation       |
| Image Segmentation | Vision processing         |
| Supply Chains      | Distribution optimization |

---

# ğŸ”¹ 8. MAX FLOW vs MIN CUT THEOREM (THEORY QUESTION âœ…)

---

## âœ… Statement

> The **maximum flow** from source to sink is equal to the **minimum cut capacity** of the network.

âœ… This theorem guarantees that Fordâ€“Fulkerson always gives the correct answer.

---

# ğŸ”¹ 9. FORDâ€“FULKERSON vs DIJKSTRA / BELLMAN (COMMON CONFUSION)

| Algorithm      | Purpose                      |
| -------------- | ---------------------------- |
| Dijkstra       | Shortest path                |
| Bellmanâ€“Ford   | Shortest path with negatives |
| Fordâ€“Fulkerson | **Maximum Flow**             |

âœ… They solve **completely different problems**

---

# ğŸ”¹ 10. ADVANTAGES & DISADVANTAGES

---

## âœ… Advantages

âœ” Simple to understand
âœ” Works well for medium graphs
âœ” Foundation of many flow algorithms

---

## âŒ Disadvantages

âŒ Can be slow for large capacities
âŒ Depends on augmenting path selection
âŒ Worst case can be inefficient

---

# ğŸ”¹ 11. COMPLETE SUMMARY TABLE

| Term              | Meaning                  |
| ----------------- | ------------------------ |
| Capacity          | Maximum allowed flow     |
| Flow              | Actual flow through edge |
| Residual Capacity | Remaining capacity       |
| Augmenting Path   | Path to increase flow    |
| Max Flow          | Maximum possible flow    |

---

# ğŸ”¹ 12. MOST IMPORTANT EXAM QUESTIONS âœ…âœ…âœ…

---

## âœ… 2 Marks

* Define Flow Network
* What is an Augmenting Path?
* What is Maximum Flow?

---

## âœ… 5 Marks

* Explain Residual Graph
* Explain Bottleneck Capacity
* Applications of Max Flow

---

## âœ… 10 Marks (ğŸ”¥ GUARANTEED NUMERICAL / THEORY)

1. Explain **Fordâ€“Fulkerson Algorithm with example**
2. Find **Maximum Flow for a given network**
3. Explain **Maxâ€“Flow Minâ€“Cut Theorem**
4. Applications of **Network Flow**

---






